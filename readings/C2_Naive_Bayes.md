# Natural Language Processing

# Table of contents
- [Table of contents](#table-of-contents)
- [1. Probability](#1-probability)
  - [1.1. Introduction to Prob](#11-introduction-to-prob)
  - [1.2. Conditional Prob](#12-conditional-prob)
  - [1.3. Bayes' Rule](#13-bayes-rule)

# 1. Probability
## 1.1. Introduction to Prob
- `N`: Total number of tweet (In this example is 20)
- `N_pos`: Total number of positive tweet
- `P(A)` = prob of positive tweets 
<p align="center">
<img src="https://user-images.githubusercontent.com/64508435/161574869-a7afc8a4-2aae-47ab-b0b6-936a87e04af6.png" width="600" />
</p>

- `P(B)` = prob of tweets contain the word "happy"
<p align="center">
<img src="https://user-images.githubusercontent.com/64508435/161575054-21084164-09e2-433d-a7e8-ce56cf032a36.png" width="600" />
</p>

- `P(A and B)` = The prob of positive tweets and tweets contains "Happy"
<p align="center">
<img src="https://user-images.githubusercontent.com/64508435/161575517-36e321e7-17b8-431e-9138-4f45e56302c0.png" width="600" />
</p>

## 1.2. Conditional Prob
<p align="center">
<img width="400" alt="image" src="https://user-images.githubusercontent.com/64508435/161575916-0bd09d85-9e24-4dab-b7a2-92cc39d47266.png">
</p>

## 1.3. Bayes' Rule
<p align="center">
<img src="https://user-images.githubusercontent.com/64508435/161576372-a65836e2-585e-40ef-b9e9-3be721cd322f.png" width="500" />
</p>

# Resources
## Reading List

[(Back to top)](#table-of-contents)
